{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from netaddr import *\n",
    "import urllib, urllib2, json\n",
    "import os, glob\n",
    "from collections import defaultdict\n",
    "import multiprocessing\n",
    "from bs4 import BeautifulSoup\n",
    "import wget\n",
    "from tinydb import TinyDB, Query\n",
    "\n",
    "BGP_LOOKING_GLASS_URL=\"https://stat.ripe.net/data/looking-glass/data.json?resource=\"\n",
    "URL_IRREXPLORER = \"http://irrexplorer.nlnog.net/json/prefix/\"\n",
    "IPSETS_PATH = \"data/ipsets/subset/\"\n",
    "IPRESOURCES_PATH = \"ftp://ftp.afrinic.net/stats/afrinic/delegated-afrinic-extended-latest\"\n",
    "BOGON_URL = \"https://www.cidr-report.org/as2.0/#Bogons\"\n",
    "BOGUS_AS_URL = \"https://www.cidr-report.org/as2.0/bogus-as-advertisements.html\"\n",
    "\n",
    "#load bogons prefixes\n",
    "def fetchBogonPrefixes(url):\n",
    "    try:\n",
    "        res = urllib2.urlopen(url)\n",
    "    except Exception, e:\n",
    "        print e\n",
    "    \n",
    "    mydict = {}\n",
    "    \n",
    "    soup = BeautifulSoup(res, \"html.parser\")\n",
    "    uls = soup.findAll(\"ul\")\n",
    "    myul = None\n",
    "    for ul in uls:\n",
    "        h3 = ul.find('h3')\n",
    "        if (h3 and h3.text == \"Possible Bogus Routes\"):\n",
    "            myul = ul\n",
    "            break\n",
    "    \n",
    "    bogons = []\n",
    "    for row in myul.findAll('tr'):\n",
    "        myrow = []\n",
    "        for td in row:\n",
    "            if td.text:\n",
    "                myrow.append(td.text)\n",
    "            elif td.find('a'):\n",
    "                myrow.append(td.find('a').text)\n",
    "            else:\n",
    "                myrow.append(\"NULL\")\n",
    "        bogons.append(myrow)\n",
    "    \n",
    "    return bogons\n",
    "\n",
    "#load bogons prefixes\n",
    "def fetchBogonAS(url):\n",
    "    try:\n",
    "        res = urllib2.urlopen(url)\n",
    "    except Exception, e:\n",
    "        print e\n",
    "        \n",
    "    soup = BeautifulSoup(res, \"html.parser\")\n",
    "    trs = soup.findAll('tr')\n",
    "    \n",
    "    bogons = []\n",
    "    for tr in trs:\n",
    "        row = []\n",
    "        for td in tr.findAll('td'):\n",
    "            row.append(td.text)\n",
    "        \n",
    "        bogons.append(row)\n",
    "    \n",
    "    return bogons\n",
    "      \n",
    "#get the number of objects found in the IRR databases\n",
    "def findIRRObjects(prefix):\n",
    "    url = URL_IRREXPLORER + prefix\n",
    "    response = urllib2.urlopen(url)\n",
    "    data = json.loads(response.read())\n",
    "    return len(data)\n",
    "\n",
    "def findBLIPs(filename):\n",
    "    with open(filename) as fp:\n",
    "        for line in fp:\n",
    "            if line.startswith(\"#\"):\n",
    "                continue\n",
    "            ipn = IPNetwork(line)\n",
    "            s = IPSet(ipn)\n",
    "            if afrinicPrefixes.intersection(s):\n",
    "                print (ipn, filename)\n",
    "\n",
    "def loadAFRINICResources(filepath, db):\n",
    "    \n",
    "    asn = db.table('asn')\n",
    "    ipv4 = db.table('ipv4')\n",
    "    ipv6 = db.table('ipv6')\n",
    "    \n",
    "    ranges = IPSet()\n",
    "    \n",
    "    with open(filepath) as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter='|')\n",
    "        \n",
    "        #skip header\n",
    "        next(csvfile, None)\n",
    "        next(csvfile, None)\n",
    "        next(csvfile, None)\n",
    "        next(csvfile, None)\n",
    "        \n",
    "        for p in reader:\n",
    "            \n",
    "            cc = p[1]\n",
    "            rtype = p[2]\n",
    "            resource = p[3]\n",
    "            prefix_length = p[4]\n",
    "            reg_date = p[5]\n",
    "            status = p[6]\n",
    "            \n",
    "            if (rtype == 'asn'):\n",
    "                asn.insert({'as': resource, 'cc': cc, 'reg_date': reg_date, 'status': status })\n",
    "            elif (rtype == 'ipv4'):\n",
    "                startip = IPAddress(resource)\n",
    "                endipint = int(startip) + int(prefix_length) - 1\n",
    "                endip = IPAddress(endipint)\n",
    "                iprange = IPRange(startip, endip)\n",
    "                ipv4.insert({'prefix': str(iprange.cidrs()[0]), 'cc': cc, 'reg_date': reg_date, 'status': status })\n",
    "            elif (rtype == 'ipv6'):\n",
    "                ipv6.insert({'prefix': resource + \"/\" + prefix_length  , 'cc': cc, 'reg_date': reg_date, 'status': status })\n",
    " \n",
    "                \n",
    "def loadAFRINICPrefixes(filepath):\n",
    "    ranges = IPSet()\n",
    "    with open(filepath) as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter='|')\n",
    "        for p in reader:\n",
    "            prefix = p[3]\n",
    "            prefixlength = p[4]\n",
    "            startip = IPAddress(prefix)\n",
    "            endipint = int(startip) + int(prefixlength) -1\n",
    "            endip = IPAddress(endipint)\n",
    "            range = IPRange(startip, endip)\n",
    "            ranges.add(range.cidrs()[0])\n",
    "    return ranges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = TinyDB('data/db.json')\n",
    "#resources = db.table('resources')\n",
    "#bogus_as = db.table('bogus_as')\n",
    "#bogus_prefixes = db.table('bogus_prefixes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print \"downloading delegated file\"\n",
    "#urllib.urlcleanup()\n",
    "#urllib.urlretrieve(IPRESOURCES_PATH, \"data/delegated.txt\")\n",
    "\n",
    "#print \"loading AFRINIC prefixes\"\n",
    "loadAFRINICResources('data/delegated.txt', db)\n",
    "\n",
    "db.ipv4.all()\n",
    "\n",
    "\n",
    "#print \"fetching bogon prefixes\"\n",
    "#bogonPrefixes = fetchBogonPrefixes(BOGON_URL)\n",
    "\n",
    "#print \"fetching bogus ASs\"\n",
    "#bogonASs = fetchBogonAS(BOGUS_AS_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
